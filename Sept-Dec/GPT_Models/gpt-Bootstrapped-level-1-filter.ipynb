{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sacremoses\nfrom transformers import pipeline","metadata":{"_uuid":"23470283-7de1-4aee-853f-59bc6c365dbb","_cell_guid":"78676d04-8536-4ac0-a960-ade39ed9849b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T19:41:39.475297Z","iopub.execute_input":"2023-11-02T19:41:39.475979Z","iopub.status.idle":"2023-11-02T19:42:18.972413Z","shell.execute_reply.started":"2023-11-02T19:41:39.475919Z","shell.execute_reply":"2023-11-02T19:42:18.970833Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2023.6.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.3.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.66.1)\nInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BioGptForSequenceClassification, BioGptTokenizer\n\nmodel_name = \"stanford-crfm/BioMedLM\"\nmodel = BioGptForSequenceClassification.from_pretrained(model_name, num_labels=3, problem_type=\"multi_label_classification\")\ntokenizer = BioGptTokenizer.from_pretrained(model_name)\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)","metadata":{"_uuid":"52abbbee-61e6-4501-bc6f-32cf3c3d1951","_cell_guid":"656db8ab-f766-452b-98da-717cac1c869c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T19:42:18.975186Z","iopub.execute_input":"2023-11-02T19:42:18.975655Z","iopub.status.idle":"2023-11-02T19:42:34.692764Z","shell.execute_reply.started":"2023-11-02T19:42:18.975614Z","shell.execute_reply":"2023-11-02T19:42:34.691489Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d4abcd6cab415686cea4034b431b64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82dd43c4759b494aade887947538fb46"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fa1d2a6550c497fb4e427792bdfb42c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5303ba6d76c2439284ac97980c142e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"184aba3531764aa8bae187a7b63ffaf2"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport pandas as pd","metadata":{"_uuid":"279ce8ca-bcbe-4377-b7bc-8e31004fbe0c","_cell_guid":"9f10dd20-ccac-4b90-9ee3-033af64c46b0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T19:42:56.723322Z","iopub.execute_input":"2023-11-02T19:42:56.723875Z","iopub.status.idle":"2023-11-02T19:42:56.732588Z","shell.execute_reply.started":"2023-11-02T19:42:56.723834Z","shell.execute_reply":"2023-11-02T19:42:56.730282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_decision(question):\n    inputs = tokenizer(question, return_tensors=\"pt\", max_length=512, truncation=True)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    predicted_class_idx = outputs.logits.argmax(dim=-1).item()\n    \n    return predicted_class_idx","metadata":{"_uuid":"4efe4fc0-64e2-41cf-9699-8efeb2b8b931","_cell_guid":"b4c17ab3-c2e2-4787-abd1-798ad8b28a86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T19:42:58.715367Z","iopub.execute_input":"2023-11-02T19:42:58.715931Z","iopub.status.idle":"2023-11-02T19:42:58.724766Z","shell.execute_reply.started":"2023-11-02T19:42:58.715874Z","shell.execute_reply":"2023-11-02T19:42:58.722770Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MAX_TOKENS = 512\n\ndef truncate_text_to_fit(text, max_tokens=MAX_TOKENS):\n    token_count = len(tokenizer.tokenize(text))\n    if token_count > max_tokens - 2:  \n        truncated_text = \" \".join(text.split()[:-1])\n        while len(tokenizer.tokenize(truncated_text)) > max_tokens - 2:\n            truncated_text = \" \".join(truncated_text.split()[:-1])\n    else:\n        truncated_text = text\n        \n    return truncated_text","metadata":{"_uuid":"810b1ff5-08a6-4a27-94fa-150f3ea4cbe8","_cell_guid":"3a4e365b-a94b-48c6-aa11-4badaa4a3018","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T19:43:01.474577Z","iopub.execute_input":"2023-11-02T19:43:01.475133Z","iopub.status.idle":"2023-11-02T19:43:01.484600Z","shell.execute_reply.started":"2023-11-02T19:43:01.475088Z","shell.execute_reply":"2023-11-02T19:43:01.483195Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_input_text(question, context):\n    input_text = \"question: \"+ question + \"context: \" + context\n    return input_text","metadata":{"_uuid":"eabb2ce8-f580-433f-8cee-998ca495bc65","_cell_guid":"98a4eb60-b1ab-4217-a869-f321078ba2a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T19:43:08.519974Z","iopub.execute_input":"2023-11-02T19:43:08.520465Z","iopub.status.idle":"2023-11-02T19:43:08.528084Z","shell.execute_reply.started":"2023-11-02T19:43:08.520428Z","shell.execute_reply":"2023-11-02T19:43:08.526337Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def save_to_csv(patient_id,indexes, pubids, results):\n    df = pd.DataFrame({\n        'Index': indexes,\n        'PubID': pubids,\n        'Result': results\n    })\n    df.to_csv(str(patient_id)+'-results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:43:10.672576Z","iopub.execute_input":"2023-11-02T19:43:10.673604Z","iopub.status.idle":"2023-11-02T19:43:10.681711Z","shell.execute_reply.started":"2023-11-02T19:43:10.673539Z","shell.execute_reply":"2023-11-02T19:43:10.680303Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"patient_histories_path = '/kaggle/input/gpt-patient/Patient_Histories_Cleaned.csv'\npatient_histories_df = pd.read_csv(patient_histories_path)\n\nfor patient_id, patient_history in patient_histories_df[['Patient ID', 'Patient History']].values:\n    patient_number = patient_id.replace(\"Patient-\", \"number\")\n    summarized_abstracts_path = f'/kaggle/input/gpt-patient/summarized_patient_cases_gpt/summarized_patient_cases_gpt/summarized_patient-{patient_number}-articles.csv'\n    summarized_abstracts_df = pd.read_csv(summarized_abstracts_path)\n    summarized_abstracts_df = summarized_abstracts_df.dropna()\n    summarized_abstracts_df['input_text']=  summarized_abstracts_df['Summary'].apply(lambda context: create_input_text(patient_history, context))\n    results = []\n    pubids = []\n    indexes = []\n    for idx, row in summarized_abstracts_df.iterrows():\n            indexes.append(idx + 1)\n            pubids.append(row['ID'])\n            results.append(classifier(truncate_text_to_fit(row['input_text'])))\n\n    if results:\n            save_to_csv(patient_id,indexes, pubids, results)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:44:26.013342Z","iopub.execute_input":"2023-11-02T19:44:26.013889Z","iopub.status.idle":"2023-11-02T20:13:03.289639Z","shell.execute_reply.started":"2023-11-02T19:44:26.013847Z","shell.execute_reply":"2023-11-02T20:13:03.288291Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\n\nlabel_mapping = {\n    \"LABEL_0\": \"yes\",\n    \"LABEL_1\": \"no\",\n    \"LABEL_2\": \"maybe\"\n}\n\ndef map_label(result_str):\n    try:\n        result_str = result_str.replace(\"'\", '\"')\n        result = json.loads(result_str)\n        label = result[0]['label']\n        return label_mapping.get(label, \"Unknown\")\n    except:\n        return \"Error in processing\"\n\n# Loop through each file\nfor i in range(1, 17):\n    file_name = f\"/kaggle/working/Patient-{i}-results.csv\"\n    \n    try:\n        # Read the file\n        decisions = pd.read_csv(file_name)\n        \n        # Apply the map_label function\n        decisions['Result'] = decisions['Result'].apply(map_label)\n        \n        # Save the file with a new suffix\n        new_file_name = f\"/kaggle/working/Patient-{i}-results-converted.csv\"\n        decisions.to_csv(new_file_name, index=False)\n        \n        # Delete the original file\n        os.remove(file_name)\n\n        print(f\"Processed, saved, and deleted: {new_file_name}\")\n\n    except FileNotFoundError:\n        print(f\"File not found: {file_name}\")","metadata":{"_uuid":"0990b2dd-a3b7-454c-913e-d7d30158ebd4","_cell_guid":"a34275e5-665e-45f5-a3ee-a84cad7eb96d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-02T20:13:08.046304Z","iopub.execute_input":"2023-11-02T20:13:08.046873Z","iopub.status.idle":"2023-11-02T20:13:08.141502Z","shell.execute_reply.started":"2023-11-02T20:13:08.046823Z","shell.execute_reply":"2023-11-02T20:13:08.139626Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Processed, saved, and deleted: /kaggle/working/Patient-1-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-2-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-3-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-4-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-5-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-6-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-7-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-8-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-9-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-10-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-11-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-12-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-13-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-14-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-15-results-converted.csv\nProcessed, saved, and deleted: /kaggle/working/Patient-16-results-converted.csv\n","output_type":"stream"}]}]}