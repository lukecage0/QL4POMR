{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6939553,"sourceType":"datasetVersion","datasetId":3985277}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom transformers import GPT2Model, GPT2Tokenizer\n\n# Define the Siamese Network using GPT-2\nclass SiameseGPT2Network(nn.Module):\n    def __init__(self):\n        super(SiameseGPT2Network, self).__init__()\n        self.gpt2 = GPT2Model.from_pretrained('gpt2')\n        self.similarity_layer = nn.Sequential(\n            nn.Linear(self.gpt2.config.n_embd * 2, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n        outputs1 = self.gpt2(input_ids=input_ids1, attention_mask=attention_mask1)\n        outputs2 = self.gpt2(input_ids=input_ids2, attention_mask=attention_mask2)\n\n        pooled_output1 = torch.mean(outputs1.last_hidden_state, dim=1)\n        pooled_output2 = torch.mean(outputs2.last_hidden_state, dim=1)\n\n        # Ensure that the batch sizes are the same\n        min_batch_size = min(pooled_output1.size(0), pooled_output2.size(0))\n        pooled_output1 = pooled_output1[:min_batch_size, :]\n        pooled_output2 = pooled_output2[:min_batch_size, :]\n\n        combined_output = torch.cat((pooled_output1, pooled_output2), 1)\n        similarity_score = self.similarity_layer(combined_output)\n        return similarity_score\n\n# Initialize tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = SiameseGPT2Network()\ntokenizer.pad_token = tokenizer.eos_token\n# Function to tokenize sentences","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T01:21:14.679369Z","iopub.execute_input":"2023-12-19T01:21:14.680499Z","iopub.status.idle":"2023-12-19T01:21:28.864388Z","shell.execute_reply.started":"2023-12-19T01:21:14.680458Z","shell.execute_reply":"2023-12-19T01:21:28.862955Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d6737e5a4aa48da925428745bff9dec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9091a0ed624f1f9755c3085e70b185"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db63780f06854e4f8564ea73eeaf3efb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1065c0d41f4ab6be12858aef9d2ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643cb37cf7134f7697aba93b85994af1"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\nfile_path = '/kaggle/input/complete-dataset/summarized_abstracts_bert/summarized_patient-number2-articles.csv'\ndf = pd.read_csv(file_path)\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nimport pandas as pd\nimport string\n\n# Ensure you have the NLTK punkt tokenizer downloaded in your environment\nnltk.download('punkt')\n\n# Function to split text into sentences and remove punctuation\ndef split_into_sentences(text):\n    return sent_tokenize(text) if pd.notna(text) else []\n\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', string.punctuation))\n\n# Load your CSV file\nfile_path = '/kaggle/input/complete-dataset/summarized_abstracts_gpt/summarized_patient-number2-articles.csv'  # Update with your file path\ndf = pd.read_csv(file_path)\n\n# Process the summaries to split into sentences and remove punctuation\narticles_sentences_cleaned = []\npubIds=df['ID'].tolist()\nfor summary in df['Summary']:\n    if pd.notna(summary):\n        sentences = split_into_sentences(summary)\n        cleaned_sentences = [remove_punctuation(sentence) for sentence in sentences]\n        articles_sentences_cleaned.append(cleaned_sentences)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T01:21:28.866334Z","iopub.execute_input":"2023-12-19T01:21:28.866797Z","iopub.status.idle":"2023-12-19T01:21:30.884291Z","shell.execute_reply.started":"2023-12-19T01:21:28.866768Z","shell.execute_reply":"2023-12-19T01:21:30.883440Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"articles_sentences_cleaned[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T01:21:30.885811Z","iopub.execute_input":"2023-12-19T01:21:30.886532Z","iopub.status.idle":"2023-12-19T01:21:30.894502Z","shell.execute_reply.started":"2023-12-19T01:21:30.886492Z","shell.execute_reply":"2023-12-19T01:21:30.893337Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['Acute pericarditis is a rare complication of percutaneous coronary intervention PCI',\n 'Here we describe a case of PCI complicated by guidewire perforation and contrast extravasation',\n 'Acute pericarditis developed 36 hours after PCI procedure with fever and severe chest pain',\n 'Electrocardiogram showed ST elevation in inferiorlateral leads',\n 'However the followup coronary angiography showed negative result and the symptom improved dramatically with the treatment of nonsteroidal antiinflammatory drug treatment',\n 'Therefore it is important for the clinician to differentiate acute myocardial infarction  acute stent thrombosis from this rare complication after PCI']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(sentences, tokenizer):\n    max_length = 128  # You can adjust this based on your data\n    return tokenizer(sentences, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n\n# Example data (lists of lists)\npatient_history_sentences = [\n        \"A 65-year-old woman arrives to the ED complaining of chest pain\",\n        \"Her past medical history includes hypertension atherosclerosis, and coronary artery disease\",\n        \"She underwent a coronary artery bypass graft (CABG) 3 weeks ago for three-vessel disease\",\n        \"She reports that her chest pain worsens with inspiration and lessens when leaning forward.\",\n        \"A friction rub is heard on auscultation\",\n        \"ECG shows global ST elevation\"\n    ]\n\n# Process and compute similarity scores\noverall_similarities = []\nfor article_sentence in articles_sentences_cleaned:\n    tokenized_article= tokenize(article_sentence, tokenizer)\n    history_similarities = []\n    for history_sentence in patient_history_sentences:\n        tokenized_history = tokenize(history_sentence, tokenizer)\n        with torch.no_grad():\n            similarity_score = model(\n                input_ids1=tokenized_history['input_ids'],\n                attention_mask1=tokenized_history['attention_mask'],\n                input_ids2=tokenized_article['input_ids'],\n                attention_mask2=tokenized_article['attention_mask']\n            )\n            history_similarities.append(similarity_score.mean().item())\n    overall_similarity = sum(history_similarities) / len(history_similarities) if history_similarities else 0\n    overall_similarities.append(overall_similarity)\n\n    \n# Print results\nentropy_df = pd.DataFrame({'PubId': pubIds, 'Entropy_score': overall_similarities})\nprint(entropy_df.head())\n# Save to CSV\ncsv_file_path = 'entropy_score.csv'\nentropy_df.to_csv(csv_file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T01:21:30.897040Z","iopub.execute_input":"2023-12-19T01:21:30.897718Z","iopub.status.idle":"2023-12-19T01:22:18.993898Z","shell.execute_reply.started":"2023-12-19T01:21:30.897677Z","shell.execute_reply":"2023-12-19T01:22:18.992695Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"      PubId  Entropy_score\n0  23388234       0.728859\n1  17921916       0.727644\n2  34067941       0.763335\n3  35018605       0.762927\n4  32856192       0.774622\n","output_type":"stream"}]},{"cell_type":"code","source":"print(overall_similarities)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T01:22:18.995864Z","iopub.execute_input":"2023-12-19T01:22:18.996236Z","iopub.status.idle":"2023-12-19T01:22:19.001759Z","shell.execute_reply.started":"2023-12-19T01:22:18.996203Z","shell.execute_reply":"2023-12-19T01:22:19.000633Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0.7288590371608734, 0.7276435891787211, 0.7633351385593414, 0.7629267772038778, 0.7746218045552572]\n","output_type":"stream"}]}]}