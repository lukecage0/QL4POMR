{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sacremoses\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-05T17:12:22.525226Z","iopub.execute_input":"2023-11-05T17:12:22.525658Z","iopub.status.idle":"2023-11-05T17:12:34.969266Z","shell.execute_reply.started":"2023-11-05T17:12:22.525628Z","shell.execute_reply":"2023-11-05T17:12:34.967405Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2023.6.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.3.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.66.1)\nInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Directory paths\nbootstrapped_level_1_path = '/kaggle/input/botstrapped-level-2-gpt/BootStrapped-Level-2-GPT/BootStrapped-Level-1-filter-Gpt'\nsummarized_abstracts_path = '/kaggle/input/botstrapped-level-2-gpt/BootStrapped-Level-2-GPT/summarized_abstracts_gpt'\npatient_histories_path = '/kaggle/input/botstrapped-level-2-gpt/BootStrapped-Level-2-GPT/Patient_Histories_Cleaned.csv'","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:12:34.971200Z","iopub.execute_input":"2023-11-05T17:12:34.971771Z","iopub.status.idle":"2023-11-05T17:12:34.979275Z","shell.execute_reply.started":"2023-11-05T17:12:34.971735Z","shell.execute_reply":"2023-11-05T17:12:34.977302Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Function to extract patient number from file name\ndef extract_patient_number(filename):\n    # Extracting the patient number from filenames like 'summarized_patient-numberX-articles.csv'\n    # or 'Patient-X-results-with-links.csv'\n    parts = filename.split('-')\n    for part in parts:\n        if part.isdigit():\n            return part\n    return None\n\n# Load the patient histories data\npatient_histories_df = pd.read_csv(patient_histories_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:12:34.980759Z","iopub.execute_input":"2023-11-05T17:12:34.981096Z","iopub.status.idle":"2023-11-05T17:12:35.016902Z","shell.execute_reply.started":"2023-11-05T17:12:34.981074Z","shell.execute_reply":"2023-11-05T17:12:35.015398Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import BioGptForSequenceClassification, BioGptTokenizer\n\nmodel_name = \"stanford-crfm/BioMedLM\"\nmodel = BioGptForSequenceClassification.from_pretrained(model_name, num_labels=3, problem_type=\"multi_label_classification\")\ntokenizer = BioGptTokenizer.from_pretrained(model_name)\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:12:35.020358Z","iopub.execute_input":"2023-11-05T17:12:35.020818Z","iopub.status.idle":"2023-11-05T17:14:46.746506Z","shell.execute_reply.started":"2023-11-05T17:12:35.020784Z","shell.execute_reply":"2023-11-05T17:14:46.742966Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/876 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7b7e20d4754d1ea436d6feff47d976"}},"metadata":{}},{"name":"stderr","text":"You are using a model of type gpt2 to instantiate a model of type biogpt. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/10.7G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0aa4740e1b34cf8a0fca301e258bf20"}},"metadata":{}},{"name":"stderr","text":"Some weights of BioGptForSequenceClassification were not initialized from the model checkpoint at stanford-crfm/BioMedLM and are newly initialized: ['layers.4.self_attn.out_proj.weight', 'layers.6.self_attn.v_proj.bias', 'layers.9.fc2.weight', 'layers.7.self_attn.q_proj.bias', 'layers.20.final_layer_norm.bias', 'layers.19.self_attn.v_proj.weight', 'layers.15.self_attn.q_proj.weight', 'layers.20.self_attn_layer_norm.bias', 'layers.18.self_attn.out_proj.bias', 'layers.21.fc1.weight', 'layers.9.self_attn.v_proj.bias', 'layers.16.self_attn.q_proj.bias', 'layers.3.fc2.bias', 'layers.15.final_layer_norm.weight', 'layers.8.fc1.bias', 'layers.18.final_layer_norm.weight', 'layers.20.self_attn_layer_norm.weight', 'layers.1.self_attn.k_proj.bias', 'layers.20.fc2.bias', 'layers.0.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.20.self_attn.v_proj.bias', 'layers.19.fc1.weight', 'layers.14.self_attn.out_proj.weight', 'layers.21.self_attn.out_proj.weight', 'layers.3.self_attn.out_proj.weight', 'layers.11.self_attn.v_proj.bias', 'layers.2.self_attn_layer_norm.bias', 'layers.9.self_attn.q_proj.bias', 'layers.13.self_attn.v_proj.bias', 'layers.8.self_attn_layer_norm.weight', 'layers.5.self_attn.v_proj.weight', 'layers.4.fc2.bias', 'layers.9.fc1.bias', 'layers.6.fc1.bias', 'layers.16.self_attn.out_proj.weight', 'layers.20.self_attn.k_proj.bias', 'layers.23.final_layer_norm.bias', 'layers.9.final_layer_norm.bias', 'layers.1.self_attn.v_proj.bias', 'layers.4.self_attn_layer_norm.bias', 'layers.4.self_attn.v_proj.bias', 'layers.7.self_attn.out_proj.weight', 'layers.16.final_layer_norm.weight', 'layers.17.self_attn.v_proj.weight', 'layers.23.self_attn.k_proj.weight', 'layers.17.fc2.bias', 'layers.17.self_attn.out_proj.bias', 'layers.22.self_attn_layer_norm.weight', 'layers.3.self_attn.q_proj.weight', 'layers.22.self_attn.q_proj.weight', 'layers.15.fc1.weight', 'layers.8.self_attn.out_proj.weight', 'layers.15.fc1.bias', 'layers.11.self_attn.q_proj.weight', 'layers.8.self_attn.q_proj.weight', 'layers.9.final_layer_norm.weight', 'layers.4.self_attn.q_proj.bias', 'layers.12.self_attn.out_proj.bias', 'layers.14.fc1.bias', 'layers.0.self_attn.q_proj.bias', 'layers.12.self_attn.v_proj.bias', 'layers.18.self_attn.v_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.12.self_attn_layer_norm.weight', 'layers.6.self_attn.out_proj.bias', 'layers.0.final_layer_norm.weight', 'layers.13.fc2.bias', 'layers.23.fc2.bias', 'layers.23.fc2.weight', 'layers.16.final_layer_norm.bias', 'layers.23.self_attn.out_proj.weight', 'layers.2.self_attn.q_proj.bias', 'layers.12.self_attn.q_proj.bias', 'layers.9.self_attn.k_proj.bias', 'layers.2.self_attn.out_proj.weight', 'layers.14.self_attn.out_proj.bias', 'layers.16.self_attn.k_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.9.self_attn_layer_norm.weight', 'layers.21.self_attn.out_proj.bias', 'layers.15.self_attn.v_proj.weight', 'layers.21.self_attn_layer_norm.bias', 'layers.22.fc1.bias', 'layers.8.self_attn.k_proj.weight', 'layers.23.self_attn.k_proj.bias', 'layers.23.self_attn.v_proj.weight', 'layers.23.self_attn.q_proj.weight', 'layers.10.fc1.weight', 'layers.8.self_attn.out_proj.bias', 'layers.8.self_attn.v_proj.bias', 'layers.16.self_attn_layer_norm.bias', 'layers.14.final_layer_norm.weight', 'layers.6.self_attn.k_proj.bias', 'layers.21.self_attn.v_proj.bias', 'layers.18.fc1.bias', 'layers.22.self_attn.v_proj.weight', 'layers.11.fc1.weight', 'layers.3.self_attn_layer_norm.bias', 'layers.10.final_layer_norm.weight', 'layers.5.final_layer_norm.weight', 'layers.2.final_layer_norm.weight', 'layers.14.self_attn.k_proj.bias', 'layers.21.self_attn_layer_norm.weight', 'layers.13.self_attn.q_proj.bias', 'layers.19.self_attn.v_proj.bias', 'layer_norm.bias', 'layers.0.self_attn.out_proj.weight', 'layers.19.final_layer_norm.weight', 'layers.1.self_attn_layer_norm.weight', 'layers.19.self_attn_layer_norm.bias', 'layers.21.fc2.bias', 'layers.12.final_layer_norm.weight', 'layers.21.fc1.bias', 'layers.5.fc2.weight', 'layers.3.fc1.bias', 'layers.16.self_attn.v_proj.weight', 'layers.7.self_attn.k_proj.bias', 'layers.13.self_attn.q_proj.weight', 'layers.21.final_layer_norm.weight', 'layers.19.fc1.bias', 'layers.17.self_attn.k_proj.weight', 'layers.12.fc1.weight', 'layers.7.fc1.bias', 'layers.5.self_attn.v_proj.bias', 'layers.6.fc1.weight', 'layers.11.self_attn_layer_norm.weight', 'layers.11.self_attn.v_proj.weight', 'layers.16.self_attn.q_proj.weight', 'layers.4.self_attn_layer_norm.weight', 'layers.11.self_attn.q_proj.bias', 'layers.5.self_attn.q_proj.bias', 'layers.1.fc1.weight', 'layers.12.self_attn.out_proj.weight', 'layers.3.self_attn.out_proj.bias', 'layers.1.final_layer_norm.bias', 'layers.16.fc2.weight', 'layers.0.self_attn.k_proj.bias', 'layers.4.final_layer_norm.weight', 'layers.16.fc1.bias', 'layers.20.fc2.weight', 'layers.6.self_attn_layer_norm.weight', 'score.weight', 'layers.4.self_attn.k_proj.bias', 'layers.14.fc2.bias', 'layers.6.final_layer_norm.weight', 'layers.1.self_attn.q_proj.weight', 'layers.9.fc2.bias', 'layers.8.final_layer_norm.bias', 'layers.10.fc2.weight', 'layers.21.self_attn.v_proj.weight', 'layers.2.fc2.weight', 'layers.19.self_attn.q_proj.weight', 'layers.6.final_layer_norm.bias', 'layers.20.self_attn.v_proj.weight', 'layers.13.self_attn_layer_norm.bias', 'layers.4.fc1.bias', 'layers.19.final_layer_norm.bias', 'layers.12.final_layer_norm.bias', 'layers.22.fc2.weight', 'layers.0.fc2.bias', 'layers.2.self_attn_layer_norm.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.out_proj.bias', 'layers.11.self_attn.k_proj.weight', 'layers.0.final_layer_norm.bias', 'layers.19.fc2.weight', 'layers.10.self_attn_layer_norm.weight', 'layers.13.self_attn.out_proj.bias', 'layers.3.self_attn.k_proj.weight', 'layers.8.fc2.bias', 'layers.17.self_attn.k_proj.bias', 'layers.3.fc2.weight', 'layers.3.self_attn.k_proj.bias', 'layers.7.self_attn.q_proj.weight', 'layers.3.self_attn.q_proj.bias', 'layers.2.fc2.bias', 'layers.11.final_layer_norm.bias', 'layers.7.fc1.weight', 'layers.6.self_attn.q_proj.bias', 'layers.14.self_attn.q_proj.weight', 'layers.17.self_attn.out_proj.weight', 'layers.23.self_attn.v_proj.bias', 'layers.12.self_attn.v_proj.weight', 'layers.21.self_attn.q_proj.bias', 'layers.12.self_attn_layer_norm.bias', 'layers.22.fc1.weight', 'layers.9.self_attn.out_proj.weight', 'layers.15.self_attn.k_proj.bias', 'layers.7.self_attn.v_proj.bias', 'layers.13.final_layer_norm.weight', 'layers.10.self_attn_layer_norm.bias', 'layers.3.self_attn_layer_norm.weight', 'layers.2.fc1.bias', 'layers.20.final_layer_norm.weight', 'layers.20.self_attn.out_proj.bias', 'layers.5.self_attn_layer_norm.weight', 'layers.17.self_attn_layer_norm.weight', 'layers.6.self_attn.out_proj.weight', 'layers.8.self_attn.k_proj.bias', 'layers.18.fc2.bias', 'layers.3.final_layer_norm.weight', 'layers.23.fc1.bias', 'layers.19.self_attn.q_proj.bias', 'layers.4.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.bias', 'layers.5.self_attn.k_proj.weight', 'layers.11.fc1.bias', 'layers.20.self_attn.q_proj.bias', 'layers.18.final_layer_norm.bias', 'layers.6.fc2.bias', 'layers.7.self_attn.v_proj.weight', 'layers.14.self_attn.k_proj.weight', 'layers.22.self_attn.k_proj.bias', 'layers.18.self_attn_layer_norm.bias', 'layers.20.self_attn.out_proj.weight', 'layers.16.fc2.bias', 'embed_positions.weight', 'layers.18.self_attn.out_proj.weight', 'layers.7.final_layer_norm.bias', 'layers.10.self_attn.q_proj.bias', 'layers.11.self_attn.out_proj.weight', 'layers.1.self_attn.out_proj.weight', 'layers.20.fc1.bias', 'layers.13.self_attn.out_proj.weight', 'layers.19.self_attn_layer_norm.weight', 'layers.22.fc2.bias', 'layers.2.self_attn.k_proj.bias', 'layers.5.fc1.bias', 'layers.7.self_attn.out_proj.bias', 'layers.14.self_attn_layer_norm.weight', 'layers.6.self_attn.k_proj.weight', 'layers.19.self_attn.out_proj.weight', 'layers.8.self_attn.q_proj.bias', 'layers.10.fc2.bias', 'layers.20.self_attn.q_proj.weight', 'layers.8.fc1.weight', 'layers.15.self_attn.q_proj.bias', 'layers.17.self_attn.v_proj.bias', 'layers.22.final_layer_norm.bias', 'layers.14.self_attn.v_proj.bias', 'layers.0.self_attn_layer_norm.weight', 'layers.21.self_attn.k_proj.weight', 'layers.3.fc1.weight', 'layers.22.self_attn.out_proj.bias', 'layers.8.final_layer_norm.weight', 'layers.5.self_attn.out_proj.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.out_proj.weight', 'layers.15.self_attn_layer_norm.bias', 'layers.2.self_attn.v_proj.bias', 'layers.15.fc2.weight', 'layers.1.fc2.bias', 'layers.10.self_attn.k_proj.weight', 'layers.4.self_attn.out_proj.bias', 'layers.5.self_attn_layer_norm.bias', 'layers.19.fc2.bias', 'layers.10.fc1.bias', 'layers.18.self_attn.k_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.5.final_layer_norm.bias', 'layers.1.final_layer_norm.weight', 'layers.13.fc2.weight', 'layers.7.fc2.weight', 'layers.19.self_attn.k_proj.bias', 'layers.3.final_layer_norm.bias', 'layers.4.final_layer_norm.bias', 'layers.17.fc1.bias', 'embed_tokens.weight', 'layers.12.fc2.bias', 'layers.16.self_attn.k_proj.bias', 'layers.16.self_attn_layer_norm.weight', 'layer_norm.weight', 'layers.0.fc1.weight', 'layers.7.self_attn_layer_norm.weight', 'layers.11.self_attn.out_proj.bias', 'layers.21.final_layer_norm.bias', 'layers.12.fc2.weight', 'layers.2.fc1.weight', 'layers.22.self_attn.q_proj.bias', 'layers.1.self_attn_layer_norm.bias', 'layers.8.fc2.weight', 'layers.0.self_attn_layer_norm.bias', 'layers.21.self_attn.k_proj.bias', 'layers.9.self_attn_layer_norm.bias', 'layers.10.final_layer_norm.bias', 'layers.4.self_attn.k_proj.weight', 'layers.14.fc2.weight', 'layers.22.self_attn_layer_norm.bias', 'layers.7.final_layer_norm.weight', 'layers.21.fc2.weight', 'layers.23.self_attn_layer_norm.weight', 'layers.18.fc2.weight', 'layers.1.fc2.weight', 'layers.14.self_attn_layer_norm.bias', 'layers.7.self_attn.k_proj.weight', 'layers.20.self_attn.k_proj.weight', 'layers.16.self_attn.v_proj.bias', 'layers.15.final_layer_norm.bias', 'layers.11.fc2.bias', 'layers.15.self_attn_layer_norm.weight', 'layers.13.final_layer_norm.bias', 'layers.6.fc2.weight', 'layers.23.fc1.weight', 'layers.5.fc1.weight', 'layers.18.self_attn.q_proj.bias', 'layers.19.self_attn.k_proj.weight', 'layers.1.self_attn.q_proj.bias', 'layers.5.self_attn.q_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.20.fc1.weight', 'layers.23.self_attn.q_proj.bias', 'layers.17.final_layer_norm.weight', 'layers.0.self_attn.out_proj.bias', 'layers.9.self_attn.out_proj.bias', 'layers.11.fc2.weight', 'layers.10.self_attn.v_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.17.final_layer_norm.bias', 'layers.19.self_attn.out_proj.bias', 'layers.22.self_attn.k_proj.weight', 'layers.21.self_attn.q_proj.weight', 'layers.10.self_attn.k_proj.bias', 'layers.22.final_layer_norm.weight', 'layers.3.self_attn.v_proj.bias', 'layers.18.self_attn_layer_norm.weight', 'layers.9.self_attn.k_proj.weight', 'layers.7.self_attn_layer_norm.bias', 'layers.14.self_attn.q_proj.bias', 'layers.7.fc2.bias', 'layers.18.fc1.weight', 'layers.9.self_attn.q_proj.weight', 'layers.17.self_attn.q_proj.bias', 'layers.11.self_attn.k_proj.bias', 'layers.23.self_attn_layer_norm.bias', 'layers.13.fc1.bias', 'layers.22.self_attn.out_proj.weight', 'layers.5.self_attn.k_proj.bias', 'layers.11.final_layer_norm.weight', 'layers.10.self_attn.out_proj.bias', 'layers.8.self_attn.v_proj.weight', 'layers.2.final_layer_norm.bias', 'layers.13.self_attn.k_proj.weight', 'layers.5.fc2.bias', 'layers.18.self_attn.k_proj.bias', 'layers.6.self_attn_layer_norm.bias', 'layers.12.self_attn.k_proj.bias', 'layers.5.self_attn.out_proj.bias', 'layers.13.self_attn_layer_norm.weight', 'layers.22.self_attn.v_proj.bias', 'layers.23.final_layer_norm.weight', 'layers.9.fc1.weight', 'layers.0.fc1.bias', 'layers.1.self_attn.out_proj.bias', 'layers.15.fc2.bias', 'layers.13.self_attn.k_proj.bias', 'layers.17.fc2.weight', 'layers.17.fc1.weight', 'layers.4.fc1.weight', 'layers.12.self_attn.q_proj.weight', 'layers.17.self_attn_layer_norm.bias', 'layers.18.self_attn.q_proj.weight', 'layers.4.fc2.weight', 'layers.9.self_attn.v_proj.weight', 'layers.11.self_attn_layer_norm.bias', 'layers.1.self_attn.v_proj.weight', 'layers.12.fc1.bias', 'layers.0.self_attn.v_proj.weight', 'layers.2.self_attn.q_proj.weight', 'layers.14.final_layer_norm.bias', 'layers.6.self_attn.q_proj.weight', 'layers.16.self_attn.out_proj.bias', 'layers.0.fc2.weight', 'layers.17.self_attn.q_proj.weight', 'layers.2.self_attn.k_proj.weight', 'layers.1.fc1.bias', 'layers.0.self_attn.v_proj.bias', 'layers.23.self_attn.out_proj.bias', 'layers.16.fc1.weight', 'layers.12.self_attn.k_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.1.self_attn.k_proj.weight', 'layers.15.self_attn.v_proj.bias', 'layers.8.self_attn_layer_norm.bias', 'layers.13.fc1.weight', 'layers.14.fc1.weight', 'layers.15.self_attn.out_proj.weight', 'layers.2.self_attn.out_proj.bias', 'layers.10.self_attn.v_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/602k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4e2825e8494660b9adab673005e5ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/276k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ff6e502af4493cabae52b862ec352f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/267 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b854b7c1bf437d9fa7ecfb43b89f21"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \nThe class this function is called from is 'BioGptTokenizer'.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at stanford-crfm/BioMedLM and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66903b107c74de2a609646930da61e1"}},"metadata":{}}]},{"cell_type":"code","source":"def get_decision(question):\n    inputs = tokenizer(question, return_tensors=\"pt\", max_length=512, truncation=True)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    predicted_class_idx = outputs.logits.argmax(dim=-1).item()\n    \n    return predicted_class_idx\n\nMAX_TOKENS = 512\n\ndef truncate_text_to_fit(text, max_tokens=MAX_TOKENS):\n    token_count = len(tokenizer.tokenize(text))\n    if token_count > max_tokens - 2:  \n        truncated_text = \" \".join(text.split()[:-1])\n        while len(tokenizer.tokenize(truncated_text)) > max_tokens - 2:\n            truncated_text = \" \".join(truncated_text.split()[:-1])\n    else:\n        truncated_text = text\n        \n    return truncated_text\n\ndef create_input_text(context, question):\n    input_text =  \"is it a relevant diagnosis: \"+ question +  \" in this context: \" + context\n    return input_text\n\ndef create_df(patient_id,indexes, pubids, results):\n    df = pd.DataFrame({\n        'Index': indexes,\n        'PubID': pubids,\n        'Result': results\n    })\n    return df\n    #df.to_csv(str(patient_id)+'-results.csv', index=False)\n    \nlabel_mapping = {\n    \"LABEL_0\": \"yes\",\n    \"LABEL_1\": \"no\",\n    \"LABEL_2\": \"maybe\"\n}\n\ndef map_label(results):\n    try:\n        # Initialize an empty list to hold the mapped labels\n        mapped_labels = []\n        # Iterate over each result in the list\n        for result in results:\n            # Assuming each result is a list with a single dictionary,\n            # extract the label from that dictionary\n            label = result['label']\n            # Map the label and append to the list of mapped labels\n            mapped_labels.append(label_mapping.get(label, \"Unknown\"))\n        return mapped_labels[0]\n\n    except Exception as e:\n        # Return the error message for debugging\n        return f\"Error in processing: {e}\"","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:14:46.752827Z","iopub.execute_input":"2023-11-05T17:14:46.754495Z","iopub.status.idle":"2023-11-05T17:14:46.773595Z","shell.execute_reply.started":"2023-11-05T17:14:46.754428Z","shell.execute_reply":"2023-11-05T17:14:46.770471Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Loop to process and handle each patient's data individually\nfor file in os.listdir(bootstrapped_level_1_path):\n    if file.endswith('.csv'):\n        patient_number = extract_patient_number(file)\n        if patient_number is None:\n            continue\n\n        # Load and filter the result file\n        result_df = pd.read_csv(os.path.join(bootstrapped_level_1_path, file))\n        filtered_results = result_df[result_df['Result'].isin(['yes', 'maybe'])]\n\n        # Load and filter the abstracts file for this patient\n        abstracts_filename = f\"summarized_patient-number{patient_number}-articles.csv\"\n        abstracts_path = os.path.join(summarized_abstracts_path, abstracts_filename)\n        if os.path.exists(abstracts_path):\n            abstracts_df = pd.read_csv(abstracts_path)\n            filtered_abstracts = abstracts_df[abstracts_df['ID'].isin(filtered_results['PubID'])]\n        else:\n            filtered_abstracts = pd.DataFrame()\n\n        # Get the diagnosis for this patient from the patient history file\n        patient_diagnosis = patient_histories_df[patient_histories_df['Patient ID'] == f\"Patient-{patient_number}\"]['Diagnosis'].iloc[0]\n        # Combine the results and abstracts into one DataFrame and add the diagnosis as a new column\n        combined_df = pd.merge(filtered_results, filtered_abstracts, left_on='PubID', right_on='ID', how='left')\n        combined_df['Diagnosis'] = patient_diagnosis\n        combined_df['input_text'] = combined_df.apply(lambda row: create_input_text(row['Summary'], row['Diagnosis']), axis=1)\n        results = []\n        pubids = []\n        indexes = []\n        for idx, row in combined_df.iterrows():\n            indexes.append(idx + 1)\n            pubids.append(row['PubID'])\n            results.append(classifier(truncate_text_to_fit(row['input_text'])))\n\n        if results:\n            result=create_df(patient_number,indexes, pubids, results)\n            result['Result'] = result['Result'].apply(map_label)\n            new_file_name = f\"/kaggle/working/Patient-{patient_number}-final-results-gpt.csv\"\n            result.to_csv(new_file_name, index=False)\n            print(f\"Processed, and saved: {new_file_name}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:14:46.777866Z","iopub.execute_input":"2023-11-05T17:14:46.779018Z","iopub.status.idle":"2023-11-05T17:46:32.080885Z","shell.execute_reply.started":"2023-11-05T17:14:46.778963Z","shell.execute_reply":"2023-11-05T17:46:32.079539Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Processed, and saved: /kaggle/working/Patient-3-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-7-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-4-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-6-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-5-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-12-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-11-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-9-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-13-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-10-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-14-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-15-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-8-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-16-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-1-final-results-gpt.csv\nProcessed, and saved: /kaggle/working/Patient-2-final-results-gpt.csv\n","output_type":"stream"}]}]}